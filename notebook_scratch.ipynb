{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('models/recognition_networks/arch1_taskA.ckpt-550000',\n",
       " 'models/recognition_networks/arch1.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import util_recognition_network\n",
    "import util_cochlear_model\n",
    "import util_audio_transform\n",
    "\n",
    "ARCH = 1\n",
    "TASK = 'A'\n",
    "\n",
    "fn_ckpt = 'models/recognition_networks/arch{}_task{}.ckpt*'.format(ARCH, TASK)\n",
    "fn_ckpt = glob.glob(fn_ckpt)[-1].replace('.index', '')\n",
    "fn_arch = 'models/recognition_networks/arch{}.json'.format(ARCH)\n",
    "with open(fn_arch, 'r') as f_arch:\n",
    "    list_layer_dict = json.load(f_arch)\n",
    "\n",
    "fn_ckpt, fn_arch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "importlib.reload(util_recognition_network)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "if 'taskA' in fn_ckpt:\n",
    "    n_classes_dict = {\"/stimuli/labels_binary_via_int\": 517}\n",
    "else:\n",
    "    n_classes_dict = {\"/stimuli/word_int\": 794}\n",
    "\n",
    "var_scope = ''\n",
    "with tf.variable_scope(var_scope):\n",
    "    tensor_input = tf.placeholder(tf.float32, [None, 40, 20000, 1])\n",
    "    tensor_output, tensors = util_recognition_network.build_network(\n",
    "        tensor_input,\n",
    "        list_layer_dict,\n",
    "        n_classes_dict=n_classes_dict)\n",
    "\n",
    "var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=var_scope)\n",
    "var_dict = {v.name: v for v in var_list}\n",
    "\n",
    "saver = tf.train.Saver(var_list=var_list, max_to_keep=0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    var_dict_init = sess.run(var_dict)\n",
    "    saver.restore(sess, fn_ckpt)\n",
    "    var_dict_load = sess.run(var_dict)\n",
    "    \n",
    "#     save_path = fn_ckpt.replace('trash/', '')\n",
    "#     print('WRITING: {}'.format(save_path))\n",
    "#     saver_to_save.save(\n",
    "#         sess,\n",
    "#         save_path=save_path,\n",
    "#         global_step=None,\n",
    "#         latest_filename=None,\n",
    "#         meta_graph_suffix='meta',\n",
    "#         write_meta_graph=False,\n",
    "#         write_state=False,\n",
    "#         strip_default_attrs=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in var_list:\n",
    "    print(v.name, np.mean(var_dict_init[v.name]), np.mean(var_dict_load[v.name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_cos_filters_nx] using filter_spacing=`erb`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'ExpandDims_1:0' shape=(?, 40, 20000, 1) dtype=float32>,\n",
       " {'fft_input': <tf.Tensor 'exd_fft_of_input:0' shape=(?, 1, 20001) dtype=complex64>,\n",
       "  'filts_tensor': <tf.Tensor 'ExpandDims:0' shape=(1, 40, 20001) dtype=complex64>,\n",
       "  'input_real': <tf.Tensor 'Placeholder:0' shape=(?, 40000) dtype=float32>,\n",
       "  'input_signal': <tf.Tensor 'Placeholder:0' shape=(?, 40000) dtype=float32>,\n",
       "  'output_tfcoch_graph': <tf.Tensor 'ExpandDims_1:0' shape=(?, 40, 20000, 1) dtype=float32>,\n",
       "  'subbands': <tf.Tensor 'mul_subbands:0' shape=(?, 40, 20001) dtype=complex64>,\n",
       "  'subbands_ifft': <tf.Tensor 'ifft_subbands:0' shape=(?, 40, 40000) dtype=float32>,\n",
       "  'subbands_time': <tf.Tensor 'ifft_subbands:0' shape=(?, 40, 40000) dtype=float32>,\n",
       "  'subbands_time_lowpassed': <tf.Tensor 'transpose_2:0' shape=(?, 40, 20000) dtype=float32>,\n",
       "  'subbands_time_lowpassed_compressed': <tf.Tensor 'ExpandDims_1:0' shape=(?, 40, 20000, 1) dtype=float32>,\n",
       "  'subbands_time_processed': <tf.Tensor 'ExpandDims_1:0' shape=(?, 40, 20000, 1) dtype=float32>,\n",
       "  'subbands_time_relu': <tf.Tensor 'rectified_subbands:0' shape=(?, 40, 40000) dtype=float32>})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import util_cochlear_model\n",
    "importlib.reload(util_cochlear_model)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tensor_waveform = tf.placeholder(tf.float32, [None, 40000])\n",
    "\n",
    "util_cochlear_model.build_cochlear_model(\n",
    "    tensor_waveform,\n",
    "    signal_rate=20000,\n",
    "    filter_type='half-cosine',\n",
    "    filter_spacing='erb',\n",
    "    HIGH_LIM=8000,\n",
    "    LOW_LIM=20,\n",
    "    N=40,\n",
    "    SAMPLE_FACTOR=1,\n",
    "    bandwidth_scale_factor=1.0,\n",
    "    compression='stable_point3',\n",
    "    include_highpass=False,\n",
    "    include_lowpass=False,\n",
    "    linear_max=1.0,\n",
    "    rFFT=True,\n",
    "    rectify_and_lowpass_subbands=True,\n",
    "    return_subbands_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from models/audio_transforms/unet_A123/frontend_model.ckpt-600000\n"
     ]
    }
   ],
   "source": [
    "import util_audio_transform\n",
    "importlib.reload(util_audio_transform)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tensor_waveform = tf.placeholder(tf.float32, [None, 40000])\n",
    "\n",
    "UNET_PARAMS = {\n",
    "    \"num_initial_filters\": 24,\n",
    "    \"output_activation\": \"identity\"\n",
    "}\n",
    "\n",
    "var_scope = 'frontend_model'\n",
    "with tf.variable_scope(var_scope):\n",
    "    tensor_waveform_unet = util_audio_transform.build_unet(\n",
    "        tensor_waveform,\n",
    "        signal_rate=20000,\n",
    "        UNET_PARAMS=UNET_PARAMS)\n",
    "\n",
    "var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=var_scope)\n",
    "var_dict = {v.name: v for v in var_list}\n",
    "\n",
    "saver = tf.train.Saver(var_list=var_list, max_to_keep=0)\n",
    "\n",
    "fn_ckpt = 'models/audio_transforms/unet_A123/frontend_model.ckpt-600000'\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    var_dict_init = sess.run(var_dict)\n",
    "    saver.restore(sess, fn_ckpt)\n",
    "    var_dict_load = sess.run(var_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frontend_model/separator/conv1d_8/kernel:0 -9.457302e-06 -0.0019786328\n",
      "frontend_model/separator/conv1d_12/kernel:0 1.4399326e-05 -0.00044223526\n",
      "frontend_model/separator/conv1d_9/kernel:0 7.0753454e-06 -0.0017836875\n",
      "frontend_model/separator/conv1d_3/bias:0 0.0 0.003133187\n",
      "frontend_model/separator/conv1d_6/bias:0 0.0 -0.008983766\n",
      "frontend_model/separator/interp_10:0 0.015453177 0.0122272335\n",
      "frontend_model/separator/conv1d_5/kernel:0 -3.7155063e-05 -0.0024077457\n",
      "frontend_model/separator/conv1d_11/bias:0 0.0 -0.021831416\n",
      "frontend_model/separator/conv1d_19/bias:0 0.0 -0.029271709\n",
      "frontend_model/separator/conv1d_2/bias:0 0.0 0.0035906392\n",
      "frontend_model/separator/interp_11:0 -0.0010926673 -0.012157106\n",
      "frontend_model/separator/conv1d_20/bias:0 0.0 -0.018392818\n",
      "frontend_model/separator/conv1d_14/kernel:0 -4.1312596e-05 -0.00059503503\n",
      "frontend_model/separator/conv1d_22/kernel:0 -7.215842e-05 -0.00079732825\n",
      "frontend_model/separator/interp_4:0 -0.004335786 -0.005335737\n",
      "frontend_model/separator/conv1d/kernel:0 -0.005036404 -7.3352785e-05\n",
      "frontend_model/separator/conv1d_1/kernel:0 -0.0002909534 -0.0011836704\n",
      "frontend_model/separator/conv1d_11/kernel:0 -2.4281205e-06 -0.0011262404\n",
      "frontend_model/separator/conv1d_22/bias:0 0.0 -0.022401193\n",
      "frontend_model/separator/conv1d_18/bias:0 0.0 -0.018943999\n",
      "frontend_model/separator/conv1d_19/kernel:0 3.5632165e-05 -0.0012874927\n",
      "frontend_model/separator/interp_5:0 0.0037496618 0.0053389273\n",
      "frontend_model/separator/interp_7:0 0.0032096712 0.0026398753\n",
      "frontend_model/separator/conv1d_17/kernel:0 4.644374e-05 -0.0014058035\n",
      "frontend_model/separator/conv1d_7/kernel:0 4.205182e-05 -0.0017660615\n",
      "frontend_model/separator/conv1d_18/kernel:0 5.7406614e-05 -0.0015661665\n",
      "frontend_model/separator/conv1d_16/bias:0 0.0 -0.020802354\n",
      "frontend_model/separator/conv1d_10/bias:0 0.0 -0.032020252\n",
      "frontend_model/separator/conv1d_23/bias:0 0.0 -0.016809288\n",
      "frontend_model/separator/conv1d_4/kernel:0 5.7795096e-05 -0.002688206\n",
      "frontend_model/separator/conv1d_4/bias:0 0.0 -0.007835039\n",
      "frontend_model/separator/conv1d_24/kernel:0 0.000200154 -0.0030610906\n",
      "frontend_model/separator/conv1d_21/bias:0 0.0 -0.024341667\n",
      "frontend_model/separator/interp_8:0 -0.0013216243 -0.0061030993\n",
      "frontend_model/separator/conv1d_17/bias:0 0.0 -0.02207203\n",
      "frontend_model/separator/conv1d_7/bias:0 0.0 -0.03326212\n",
      "frontend_model/separator/conv1d_1/bias:0 0.0 0.00047317054\n",
      "frontend_model/separator/conv1d_20/kernel:0 4.8312075e-05 -0.0015393881\n",
      "frontend_model/separator/conv1d_6/kernel:0 -8.3096704e-05 -0.0016081498\n",
      "frontend_model/separator/conv1d_15/bias:0 0.0 -0.008799787\n",
      "frontend_model/separator/conv1d_21/kernel:0 -5.932115e-05 -0.0014442017\n",
      "frontend_model/separator/conv1d_12/bias:0 0.0 -0.013592381\n",
      "frontend_model/separator/conv1d_23/kernel:0 6.3203624e-05 -0.0007102519\n",
      "frontend_model/separator/conv1d_2/kernel:0 -9.0062385e-05 -0.0037330526\n",
      "frontend_model/separator/interp_9:0 0.0070900996 0.004278432\n",
      "frontend_model/separator/conv1d_3/kernel:0 -0.00017346618 -0.0028885268\n",
      "frontend_model/separator/conv1d_10/kernel:0 -7.840971e-06 -0.0010176883\n",
      "frontend_model/separator/conv1d_14/bias:0 0.0 -0.00017029498\n",
      "frontend_model/separator/interp_2:0 0.003286331 0.0043611303\n",
      "frontend_model/separator/conv1d/bias:0 0.0 0.0020257283\n",
      "frontend_model/separator/interp_6:0 0.0020321514 -0.002640332\n",
      "frontend_model/separator/conv1d_13/bias:0 0.0 0.003923736\n",
      "frontend_model/separator/interp_3:0 -0.0032799244 -0.004697745\n",
      "frontend_model/separator/conv1d_15/kernel:0 -1.1524701e-05 -0.0007085812\n",
      "frontend_model/separator/conv1d_16/kernel:0 5.2389158e-05 -0.0012000381\n",
      "frontend_model/separator/conv1d_5/bias:0 0.0 0.00072018517\n",
      "frontend_model/separator/conv1d_25/bias:0 0.0 -5.889995e-06\n",
      "frontend_model/separator/conv1d_13/kernel:0 -2.0696311e-06 -0.00091705937\n",
      "frontend_model/separator/conv1d_9/bias:0 0.0 -0.03750312\n",
      "frontend_model/separator/conv1d_25/kernel:0 -0.10548952 0.032430038\n",
      "frontend_model/separator/conv1d_8/bias:0 0.0 -0.058979932\n",
      "frontend_model/separator/interp_1:0 -0.0009205099 0.008302286\n",
      "frontend_model/separator/interp_0:0 0.00065941934 -0.00027360691\n",
      "frontend_model/separator/conv1d_24/bias:0 0.0 0.030591667\n"
     ]
    }
   ],
   "source": [
    "for k in var_dict_init.keys():\n",
    "    print(k, np.mean(var_dict_init[k]), np.mean(var_dict_load[k]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
