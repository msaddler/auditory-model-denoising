{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('models/recognition_networks/arch1_taskA.ckpt-550000',\n",
       " 'models/recognition_networks/arch1.json')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import util_recognition_network\n",
    "import util_cochlear_model\n",
    "\n",
    "ARCH = 1\n",
    "TASK = 'A'\n",
    "\n",
    "fn_ckpt = 'models/recognition_networks/arch{}_task{}.ckpt*'.format(ARCH, TASK)\n",
    "fn_ckpt = glob.glob(fn_ckpt)[-1].replace('.index', '')\n",
    "fn_arch = 'models/recognition_networks/arch{}.json'.format(ARCH)\n",
    "with open(fn_arch, 'r') as f_arch:\n",
    "    list_layer_dict = json.load(f_arch)\n",
    "\n",
    "fn_ckpt, fn_arch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "importlib.reload(util_recognition_network)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "if 'taskA' in fn_ckpt:\n",
    "    n_classes_dict = {\"/stimuli/labels_binary_via_int\": 517}\n",
    "else:\n",
    "    n_classes_dict = {\"/stimuli/word_int\": 794}\n",
    "\n",
    "var_scope = ''\n",
    "with tf.variable_scope(var_scope):\n",
    "    tensor_input = tf.placeholder(tf.float32, [None, 40, 20000, 1])\n",
    "    tensor_output, tensors = util_recognition_network.build_network(\n",
    "        tensor_input,\n",
    "        list_layer_dict,\n",
    "        n_classes_dict=n_classes_dict)\n",
    "\n",
    "var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=var_scope)\n",
    "var_dict = {v.name: v for v in var_list}\n",
    "\n",
    "saver = tf.train.Saver(var_list=var_list, max_to_keep=0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    var_dict_init = sess.run(var_dict)\n",
    "    saver.restore(sess, fn_ckpt)\n",
    "    var_dict_load = sess.run(var_dict)\n",
    "    \n",
    "#     save_path = fn_ckpt.replace('trash/', '')\n",
    "#     print('WRITING: {}'.format(save_path))\n",
    "#     saver_to_save.save(\n",
    "#         sess,\n",
    "#         save_path=save_path,\n",
    "#         global_step=None,\n",
    "#         latest_filename=None,\n",
    "#         meta_graph_suffix='meta',\n",
    "#         write_meta_graph=False,\n",
    "#         write_state=False,\n",
    "#         strip_default_attrs=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in var_list:\n",
    "    print(v.name, np.mean(var_dict_init[v.name]), np.mean(var_dict_load[v.name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_cos_filters_nx] using filter_spacing=`erb`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'ExpandDims_1:0' shape=(?, 40, 20000, 1) dtype=float32>,\n",
       " {'fft_input': <tf.Tensor 'exd_fft_of_input:0' shape=(?, 1, 20001) dtype=complex64>,\n",
       "  'filts_tensor': <tf.Tensor 'ExpandDims:0' shape=(1, 40, 20001) dtype=complex64>,\n",
       "  'input_real': <tf.Tensor 'Placeholder:0' shape=(?, 40000) dtype=float32>,\n",
       "  'input_signal': <tf.Tensor 'Placeholder:0' shape=(?, 40000) dtype=float32>,\n",
       "  'output_tfcoch_graph': <tf.Tensor 'ExpandDims_1:0' shape=(?, 40, 20000, 1) dtype=float32>,\n",
       "  'subbands': <tf.Tensor 'mul_subbands:0' shape=(?, 40, 20001) dtype=complex64>,\n",
       "  'subbands_ifft': <tf.Tensor 'ifft_subbands:0' shape=(?, 40, 40000) dtype=float32>,\n",
       "  'subbands_time': <tf.Tensor 'ifft_subbands:0' shape=(?, 40, 40000) dtype=float32>,\n",
       "  'subbands_time_lowpassed': <tf.Tensor 'transpose_2:0' shape=(?, 40, 20000) dtype=float32>,\n",
       "  'subbands_time_lowpassed_compressed': <tf.Tensor 'ExpandDims_1:0' shape=(?, 40, 20000, 1) dtype=float32>,\n",
       "  'subbands_time_processed': <tf.Tensor 'ExpandDims_1:0' shape=(?, 40, 20000, 1) dtype=float32>,\n",
       "  'subbands_time_relu': <tf.Tensor 'rectified_subbands:0' shape=(?, 40, 40000) dtype=float32>})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import util_cochlear_model\n",
    "importlib.reload(util_cochlear_model)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tensor_waveform = tf.placeholder(tf.float32, [None, 40000])\n",
    "\n",
    "util_cochlear_model.build_cochlear_model(\n",
    "    tensor_waveform,\n",
    "    signal_rate=20000,\n",
    "    filter_type='half-cosine',\n",
    "    filter_spacing='erb',\n",
    "    HIGH_LIM=8000,\n",
    "    LOW_LIM=20,\n",
    "    N=40,\n",
    "    SAMPLE_FACTOR=1,\n",
    "    bandwidth_scale_factor=1.0,\n",
    "    compression='stable_point3',\n",
    "    include_highpass=False,\n",
    "    include_lowpass=False,\n",
    "    linear_max=1.0,\n",
    "    rFFT=True,\n",
    "    rectify_and_lowpass_subbands=True,\n",
    "    return_subbands_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
