{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'util_auditory_model_loss' from '/rdma/vast-rdma/vast/mcdermott/msaddler/auditory-model-denoising/util_auditory_model_loss.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import importlib\n",
    "import IPython.display as ipd\n",
    "\n",
    "import util_audio_preprocess\n",
    "import util_audio_transform\n",
    "import util_auditory_model_loss\n",
    "import util_cochlear_model\n",
    "import util_recognition_network\n",
    "\n",
    "importlib.reload(util_auditory_model_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'snr': <tf.Tensor 'IteratorGetNext:0' shape=(?, 1) dtype=float32>,\n",
       " 'waveform_clean': <tf.Tensor 'IteratorGetNext:1' shape=(?, 40000) dtype=float32>,\n",
       " 'waveform_noisy': <tf.Tensor 'IteratorGetNext:2' shape=(?, 40000) dtype=float32>}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = glob.glob('data/toy_dataset*.tfrecords')\n",
    "batch_size = 8\n",
    "feature_description = {\n",
    "    'background/signal': tf.io.FixedLenFeature([], tf.string, default_value=None),\n",
    "    'foreground/signal': tf.io.FixedLenFeature([], tf.string, default_value=None),\n",
    "}\n",
    "bytes_description = {\n",
    "    'background/signal': {'dtype': tf.float32, 'shape': [40000]}, \n",
    "    'foreground/signal': {'dtype': tf.float32, 'shape': [40000]},\n",
    "}\n",
    "\n",
    "\n",
    "def parse_tfrecord(tfrecord):\n",
    "    tfrecord = tf.parse_single_example(tfrecord, features=feature_description)\n",
    "    for key in bytes_description.keys():\n",
    "        tfrecord[key] = tf.decode_raw(tfrecord[key], bytes_description[key]['dtype'])\n",
    "        tfrecord[key] = tf.reshape(tfrecord[key], bytes_description[key]['shape'])\n",
    "    return tfrecord\n",
    "\n",
    "\n",
    "def preprocess_audio_batch(batch):\n",
    "    foreground_signal = batch['foreground/signal']\n",
    "    background_signal = batch['background/signal']\n",
    "    snr = tf.random.uniform(\n",
    "        [tf.shape(foreground_signal)[0], 1],\n",
    "        minval=-20.0,\n",
    "        maxval=10.0,\n",
    "        dtype=foreground_signal.dtype)\n",
    "    signal_in_noise, signal, noise_scaled = util_audio_preprocess.tf_set_snr(\n",
    "        foreground_signal,\n",
    "        background_signal,\n",
    "        snr)\n",
    "    batch = {\n",
    "        'snr': snr,\n",
    "        'waveform_noisy': signal_in_noise,\n",
    "        'waveform_clean': signal,\n",
    "    }\n",
    "    return batch\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.random.set_random_seed(0)\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(filenames=filenames, compression_type='GZIP')\n",
    "dataset = dataset.map(parse_tfrecord)\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.map(preprocess_audio_batch)\n",
    "dataset = dataset.prefetch(buffer_size=4)\n",
    "dataset = dataset.shuffle(buffer_size=32)\n",
    "dataset = dataset.repeat(count=None)\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "input_tensor_dict = iterator.get_next()\n",
    "input_tensor_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From Wave-U-Net/UnetAudioSeparator.py:97: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv1d instead.\n",
      "1 recognition networks included for deep feature loss:\n",
      "|__ arch1_taskA: models/recognition_networks/arch1_taskA.ckpt-550000\n",
      "Building waveform loss\n",
      "Building cochlear model loss\n",
      "[make_cos_filters_nx] using filter_spacing=`erb`\n",
      "[make_cos_filters_nx] using filter_spacing=`erb`\n",
      "Building deep feature loss (recognition network: arch1_taskA)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/signal/fft_ops.py:315: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "tensor_waveform_noisy = input_tensor_dict['waveform_noisy']\n",
    "tensor_waveform_clean = input_tensor_dict['waveform_clean']\n",
    "with tf.variable_scope('audio_transform'):\n",
    "    tensor_waveform_denoised = util_audio_transform.build_unet(tensor_waveform_noisy)\n",
    "\n",
    "list_recognition_networks = [\n",
    "    'arch1_taskA',\n",
    "#     'arch2_taskA',\n",
    "#     'arch3_taskA',\n",
    "]\n",
    "auditory_model = util_auditory_model_loss.AuditoryModelLoss(\n",
    "    list_recognition_networks=list_recognition_networks,\n",
    "    tensor_wave0=tensor_waveform_clean,\n",
    "    tensor_wave1=tensor_waveform_denoised)\n",
    "\n",
    "transform_var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='audio_transform')\n",
    "# loss = auditory_model.loss_waveform\n",
    "# loss = auditory_model.loss_cochlear_model\n",
    "loss = auditory_model.loss_deep_features\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\n",
    "train_op = optimizer.minimize(\n",
    "    loss=loss,\n",
    "    global_step=None,\n",
    "    var_list=transform_var_list)\n",
    "\n",
    "# transform_saver = tf.train.Saver(var_list=transform_var_list, max_to_keep=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading `arch1_taskA` variables from models/recognition_networks/arch1_taskA.ckpt-550000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from models/recognition_networks/arch1_taskA.ckpt-550000\n",
      "INFO:tensorflow:Restoring parameters from models/recognition_networks/arch1_taskA.ckpt-550000\n",
      "0 2.246965\n",
      "5 2.2889702\n",
      "10 2.3068545\n",
      "15 2.0011575\n",
      "20 1.9369578\n",
      "25 1.9962149\n",
      "30 2.034226\n",
      "35 2.1364148\n",
      "40 1.9627442\n",
      "45 2.2372794\n",
      "50 1.9959297\n",
      "55 2.0009422\n",
      "60 1.8449538\n",
      "65 1.917606\n",
      "70 1.6848927\n",
      "75 1.7655628\n",
      "80 2.0259156\n",
      "85 1.8892846\n",
      "90 2.0066733\n",
      "95 1.9107757\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "#     example = sess.run(iterator.get_next())\n",
    "#     for k in example.keys():\n",
    "#         print(k, example[k].dtype, example[k].shape)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    auditory_model.load_auditory_model_vars(sess)\n",
    "    \n",
    "    for itr0 in range(100):\n",
    "        _, batch_loss = sess.run([train_op, loss])\n",
    "        if itr0 % 5 == 0:\n",
    "            print(itr0, batch_loss.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
